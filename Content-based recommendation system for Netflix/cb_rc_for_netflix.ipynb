{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Content-based recommendation system for Netflix**\n",
    "\n",
    "## Загрузка инструментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Реализуем несложную рекомендательную систему на основе данных о контенте. Будем работать с [датасетом](https://lms-cdn.skillfactory.ru/assets/courseware/v1/747dae7bf99b18ce3b24bd34aa7bc29b/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/netflix_titles.zip) (прямая ссылка), содержащим информацию об оценивании фильмов на платформе Netflix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (7787, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>João Miguel, Bianca Comparato, Michel Gomes, R...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>August 14, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>4 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Sci-Fi &amp;...</td>\n",
       "      <td>In a future where the elite inhabit an island ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>7:19</td>\n",
       "      <td>Jorge Michel Grau</td>\n",
       "      <td>Demián Bichir, Héctor Bonilla, Oscar Serrano, ...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>December 23, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>93 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After a devastating earthquake hits Mexico Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>23:59</td>\n",
       "      <td>Gilbert Chan</td>\n",
       "      <td>Tedd Chan, Stella Chung, Henley Hii, Lawrence ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>December 20, 2018</td>\n",
       "      <td>2011</td>\n",
       "      <td>R</td>\n",
       "      <td>78 min</td>\n",
       "      <td>Horror Movies, International Movies</td>\n",
       "      <td>When an army recruit is found dead, his fellow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type  title           director  \\\n",
       "0      s1  TV Show     3%                NaN   \n",
       "1      s2    Movie   7:19  Jorge Michel Grau   \n",
       "2      s3    Movie  23:59       Gilbert Chan   \n",
       "\n",
       "                                                cast    country  \\\n",
       "0  João Miguel, Bianca Comparato, Michel Gomes, R...     Brazil   \n",
       "1  Demián Bichir, Héctor Bonilla, Oscar Serrano, ...     Mexico   \n",
       "2  Tedd Chan, Stella Chung, Henley Hii, Lawrence ...  Singapore   \n",
       "\n",
       "          date_added  release_year rating   duration  \\\n",
       "0    August 14, 2020          2020  TV-MA  4 Seasons   \n",
       "1  December 23, 2016          2016  TV-MA     93 min   \n",
       "2  December 20, 2018          2011      R     78 min   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0  International TV Shows, TV Dramas, TV Sci-Fi &...   \n",
       "1                       Dramas, International Movies   \n",
       "2                Horror Movies, International Movies   \n",
       "\n",
       "                                         description  \n",
       "0  In a future where the elite inhabit an island ...  \n",
       "1  After a devastating earthquake hits Mexico Cit...  \n",
       "2  When an army recruit is found dead, his fellow...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_data = pd.read_csv('data/netflix_titles.zip')\n",
    "print('Data shape:', netflix_data.shape)\n",
    "netflix_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки в данных\n",
    "\n",
    "|features|description|features|description|\n",
    "|-|-|-|-|\n",
    "|`show_id`|id фильма|`date_added`|дата добавления|\n",
    "|`type`|его тип (фильм или сериал)|`release_year`|год выхода на экраны|\n",
    "|`title`|название|`rating`|рейтинг|\n",
    "|`director`|режиссер|`duration`|продолжительность|\n",
    "|`cast`|актерский состав|`listened_in`|жанр(-ы)|\n",
    "|`country`|страна|`description`|описание|\n",
    "\n",
    "В первую очередь нам необходимо определить, на основании чего мы будем рассматривать близость фильмов. Выберем для этой задачи описание фильма, ведь в нём, скорее всего, содержится много информации. Однако описание — это текст. Есть много подходов к преобразованию текста в вектор, и мы будем использовать подход TF-IDF (Term Frequency-Inverse Document Frequency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных\n",
    "\n",
    "Учтём стоп-слова, т.е. предлоги и другие служебные части речи, которые не несут содержательной информации, и определим нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски пустыми строками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data['description'] = netflix_data['description'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформируем наши описания в матрицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = model.fit_transform(netflix_data['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на размер получившейся матрицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (7787, 17905)\n"
     ]
    }
   ],
   "source": [
    "print('Matrix shape:', feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо вычислить косинусную близость. Можно сделать это так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно было, конечно воспользоватся [cosine_similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html#sklearn.metrics.pairwise.cosine_similarity), но эта функция в нашем случае была бы избыточной, так как повторно реализовала бы нормировку векторов.\n",
    "\n",
    "Вернём индексацию и уберём дубликаты из данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(netflix_data.index, index=netflix_data['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация рекомендательной системы: начало\n",
    "\n",
    "Теперь пропишем функцию для создания рекомендаций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores =   scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return netflix_data['title'].iloc[ind_movie]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы посмотрели фильм \"Star Trek\", и наша функция будет готова порекомендовать нам ещё несколько похожих фильмов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5788             Star Trek: The Next Generation\n",
       "5787                      Star Trek: Enterprise\n",
       "5786                 Star Trek: Deep Space Nine\n",
       "5557                     She's Out of My League\n",
       "134                                  7 Days Out\n",
       "6664                        The Midnight Gospel\n",
       "6023                                     Teresa\n",
       "4863    Pinkfong & Baby Shark's Space Adventure\n",
       "5104                                       Rats\n",
       "5970                             Tales by Light\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Star Trek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или мы посмотрели детский фильм \"Balto\", вышедшего на экраны в 1995 году, тогда рекомендация будет выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709                Balto 2: Wolf Quest\n",
       "7446                           Vroomiz\n",
       "1338    Chilling Adventures of Sabrina\n",
       "7388                          Vampires\n",
       "1770                          Dinotrux\n",
       "2767                     Hold the Dark\n",
       "5540                 Shanghai Fortress\n",
       "4041                             Mercy\n",
       "2582                       Half & Half\n",
       "1365        Christmas in the Heartland\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Balto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация рекомендательной системы: продолжение\n",
    "\n",
    "Ну хорошо, мы смоделировали такую ситуацию, что потребитель контента просмотрел один фильм и получил предложение посмотреть ещё несколько других фильмов, описание которых похоже на описание просмотренного.\n",
    "\n",
    "Но а что нам делать потом, когда потребитель просмотрит второй фильм? Делать рекомендацию лишь по последнему фильму было бы неразумно: вероятны повторные рекомендации одних и тех же фильмов. Есть выход: можно вычислить средний вектор для всех просмотренных фильмов, используя существующие векторы. Это позволит создать \"профиль\" пользователя на основе его предпочтений.\n",
    "\n",
    "Но если количество просмотренных фильмов становится большим, использование простого среднего вектора может привести к тому, что старые фильмы будут влиять на профиль пользователя слишком сильно. Чтобы учесть временной фактор и дать больший вес недавно просмотренным фильмам, можно использовать подход с взвешиванием.\n",
    "\n",
    "Вот один из способов реализовать это:\n",
    "\n",
    "1. Присвоить каждому просмотренному фильму вес в зависимости от того, как давно он был просмотрен. Например, можно использовать экспоненциальное затухание, где более свежие фильмы имеют больший вес.\n",
    "\n",
    "2. Вместо простого среднего вектора, вычислить взвешенное среднее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(viewed_data, feature_matrix):\n",
    "    # Получаем индексы просмотренных фильмов\n",
    "    titles = list(viewed_data.keys())\n",
    "    indices = netflix_data[netflix_data['title'].isin(titles)].index\n",
    "    \n",
    "    # Извлекаем векторы для просмотренных фильмов\n",
    "    viewed_vectors = feature_matrix[indices]\n",
    "    \n",
    "    # Текущая дата\n",
    "    current_date = datetime.now()\n",
    "\n",
    "    # Вычисляем разницу в днях\n",
    "    viewed_dates = list(viewed_data.values())\n",
    "    days_diff = np.array([(current_date - date).days for date in viewed_dates])\n",
    "\n",
    "    # Присваиваем веса на основе даты просмотра (ближайшие - больший вес)\n",
    "    weights = np.exp(-days_diff / 30)  # Делим на 30 для нормализации\n",
    "\n",
    "    # Вычисляем взвешенное среднее\n",
    "    weighted_average_vector = np.average(viewed_vectors.toarray(), axis=0, weights=weights)\n",
    "    \n",
    "    return weighted_average_vector, indices\n",
    "\n",
    "\n",
    "def get_recommendations_from_profile(user_profile_vector, feature_matrix, viewed_indices):\n",
    "    # Преобразуем user_profile_vector в нужный формат\n",
    "    user_profile_vector_array = user_profile_vector.reshape(1, -1)\n",
    "\n",
    "    # Вычисляем косинусное сходство между профилем пользователя и всеми фильмами\n",
    "    scores = linear_kernel(user_profile_vector_array, feature_matrix.toarray())\n",
    "    \n",
    "    # Сортируем фильмы по убыванию сходства\n",
    "    scores = list(enumerate(scores[0]))\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Возвращаем названия фильмов, исключая уже просмотренные\n",
    "    recommended_indices = [i[0] for i in scores if i[0] not in viewed_indices]\n",
    "    \n",
    "    return netflix_data['title'].iloc[recommended_indices[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что у нас получится:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709                                   Balto 2: Wolf Quest\n",
       "1338                       Chilling Adventures of Sabrina\n",
       "7446                                              Vroomiz\n",
       "7388                                             Vampires\n",
       "1770                                             Dinotrux\n",
       "2767                                        Hold the Dark\n",
       "433     Alpha and Omega: The Legend of the Saw Tooth Cave\n",
       "6286                                      The Degenerates\n",
       "5540                                    Shanghai Fortress\n",
       "5788                       Star Trek: The Next Generation\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Данные о просмотрах\n",
    "viewed_data = {\n",
    "    'Balto': datetime(2024, 9, 1),\n",
    "    'Star Trek': datetime(2024, 8, 1),\n",
    "}\n",
    "\n",
    "# Расчёт профильного вектора \n",
    "user_profile_vector, viewed_indices = get_user_profile(\n",
    "    viewed_data, feature_matrix\n",
    "    )\n",
    "# Рекомендации\n",
    "recommendations = get_recommendations_from_profile(\n",
    "    user_profile_vector, feature_matrix, viewed_indices\n",
    "    )\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, разнесённые по времени на месяц просмотры будут по-разному влиять на свежие рекомендации.\n",
    "\n",
    "Вот так простой векторизатор TF-IDF помогает реализовать content-based подход при разработке простенькой рекомендательной системы. Однако опора лишь на векторизацию текстового описания объектов для качественной генерации рекомендаций может быть недостаточно: если поменять в рассмотренном примере имена фильмов в словаре `viewed_data`, то результат не поменяется: это может происходить потому, что вектор признаков фильма \"Star Trek\" менее \"уникален\" в пространстве признаков по сравнению с \"Balto\"; но возможно, в нашей матрице признаков фильмы, похожие на \"Balto\", имеют более выраженные или уникальные характеристики, что и приводит к их доминированию в рекомендациях.\n",
    "\n",
    "Вероятно, для устранения такого рода артефактов нужно использовать больше данных о фильмах."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
